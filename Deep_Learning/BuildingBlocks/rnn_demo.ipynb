{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04eb59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95260b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Category</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>b'Khoury'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>b'Nahas'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>b'Daher'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>b'Gerges'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>b'Nazari'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>20069</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>b'Truong'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20070</th>\n",
       "      <td>20070</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>b'Van'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20071</th>\n",
       "      <td>20071</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>b'Vinh'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20072</th>\n",
       "      <td>20072</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>b'Vuong'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20073</th>\n",
       "      <td>20073</td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>b'Vuu'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20074 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    Category       Name\n",
       "0               0      Arabic  b'Khoury'\n",
       "1               1      Arabic   b'Nahas'\n",
       "2               2      Arabic   b'Daher'\n",
       "3               3      Arabic  b'Gerges'\n",
       "4               4      Arabic  b'Nazari'\n",
       "...           ...         ...        ...\n",
       "20069       20069  Vietnamese  b'Truong'\n",
       "20070       20070  Vietnamese     b'Van'\n",
       "20071       20071  Vietnamese    b'Vinh'\n",
       "20072       20072  Vietnamese   b'Vuong'\n",
       "20073       20073  Vietnamese     b'Vuu'\n",
       "\n",
       "[20074 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"resources/names.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e279a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters = [\"<pad>\"] + list(string.ascii_letters + \"/1234567890 .,;:'-\\\"\") + [\"<eos>\"]\n",
    "n_letters = len(all_letters)\n",
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc1ec35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {letter : idx for idx, letter in enumerate(all_letters)}\n",
    "itos = [letter for idx, letter in enumerate(all_letters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25627751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, '6')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi[\"<eos>\"], itos[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76865740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7501b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset(Dataset):\n",
    "    def __init__(self, df, stoi, eos_token=\"<eos>\"):\n",
    "        self.stoi = stoi\n",
    "        self.eos_token = eos_token\n",
    "        self.n_tokens = len(self.stoi)\n",
    "        \n",
    "        self.categories = df[\"Category\"].tolist()\n",
    "        self.names = df[\"Name\"].tolist()\n",
    "        \n",
    "        \n",
    "        self.all_categories = list(set(self.categories))\n",
    "        self.n_categories = len(self.all_categories)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        category = self.categories[item]\n",
    "        name = self.names[item]\n",
    "        \n",
    "        category_tensor = self.get_category_tensor(category)\n",
    "        \n",
    "        input_tensor = torch.tensor([stoi[char] for char in name])\n",
    "        target_tensor = torch.tensor([stoi[char] for char in list(name[1:])+[self.eos_token]])\n",
    "        \n",
    "        item_dict = {\"category\": category,\n",
    "        \"name\": name,\n",
    "        \"category_tensor\": category_tensor,\n",
    "        \"input_tensor\": input_tensor,\n",
    "        \"target_tensor\": target_tensor}\n",
    "        \n",
    "        \n",
    "        return item_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.categories)\n",
    "    \n",
    "    \n",
    "    def get_category_tensor(self, category):\n",
    "        li = self.all_categories.index(category)\n",
    "        tensor = torch.zeros(1, self.n_categories)\n",
    "        tensor[0][li] = 1\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfe02cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'Arabic',\n",
       " 'name': \"b'Khoury'\",\n",
       " 'category_tensor': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " 'input_tensor': tensor([ 2, 69, 37,  8, 15, 21, 18, 25, 69]),\n",
       " 'target_tensor': tensor([69, 37,  8, 15, 21, 18, 25, 69, 72])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = NamesDataset(df, stoi)\n",
    "\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "080868fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    def merge(sequences):\n",
    "        \"https://github.com/yunjey/seq2seq-dataloader/blob/master/data_loader.py\"\n",
    "        \n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
    "        for i, seq in enumerate(sequences):\n",
    "            end = lengths[i]\n",
    "            padded_seqs[i, :end] = seq[:end]\n",
    "        return padded_seqs, lengths\n",
    "\n",
    "    categories = [x[\"category\"] for x in data]          \n",
    "    names = [x[\"name\"] for x in data]          \n",
    "    category_tensors = torch.cat([x[\"category_tensor\"] for x in data])\n",
    "    \n",
    "    input_tensors = [x[\"input_tensor\"] for x in data]\n",
    "    input_tensors, _ = merge(input_tensors)\n",
    "    \n",
    "    target_tensors = [x[\"target_tensor\"] for x in data]\n",
    "    target_tensors, _ = merge(target_tensors)\n",
    "    \n",
    "    return categories, names, category_tensors, input_tensors, target_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03b1494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=1, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "256c0953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Russian'],\n",
       " [\"b'Anofriev'\"],\n",
       " tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[ 2, 69, 27, 14, 15,  6, 18,  9,  5, 22, 69]]),\n",
       " tensor([[69, 27, 14, 15,  6, 18,  9,  5, 22, 69, 72]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d819f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDatamodule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.df = pd.read_csv(\"resources/names.csv\")\n",
    "        \n",
    "        self.all_letters = all_letters = [\"<pad>\"] + list(string.ascii_letters + \" .,;'-\") + [\"<eos>\"]\n",
    "        self.stoi = {letter : idx for idx, letter in enumerate(self.all_letters)}\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_set = NamesDataset(df, self.stoi)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def collate_fn(self, data):\n",
    "        def merge(sequences):\n",
    "            \"https://github.com/yunjey/seq2seq-dataloader/blob/master/data_loader.py\"\n",
    "\n",
    "            lengths = [len(seq) for seq in sequences]\n",
    "            padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
    "            for i, seq in enumerate(sequences):\n",
    "                end = lengths[i]\n",
    "                padded_seqs[i, :end] = seq[:end]\n",
    "            return padded_seqs, lengths\n",
    "\n",
    "        categories = [x[\"category\"] for x in data]          \n",
    "        names = [x[\"name\"] for x in data]          \n",
    "        category_tensors = torch.cat([x[\"category_tensor\"] for x in data])\n",
    "\n",
    "        input_tensors = [x[\"input_tensor\"] for x in data]\n",
    "        input_tensors, _ = merge(input_tensors)\n",
    "\n",
    "        target_tensors = [x[\"target_tensor\"] for x in data]\n",
    "        target_tensors, _ = merge(target_tensors)\n",
    "        \n",
    "        item_dict = {\"categories\": categories, \n",
    "                     \"names\": names, \n",
    "                     \"category_tensors\": category_tensors,\n",
    "                     \"input_tensors\": input_tensors,\n",
    "                     \"target_tensors\": target_tensors}\n",
    "\n",
    "        return item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4339647",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(pl.LightningModule):\n",
    "    lr = 5e-4\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, embeding_size, n_categories, n_layers, output_size, p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "        self.embeding = nn.Embedding(input_size+n_categories, embeding_size)\n",
    "        self.lstm = nn.LSTM(embeding_size+n_categories, hidden_size, n_layers, dropout=p)\n",
    "        self.out_fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p)\n",
    "        \n",
    "\n",
    "    def forward(self, batch_of_category, batch_of_letter, hidden, cell):\n",
    "        ## letter level operations\n",
    "        \n",
    "        embeding = self.dropout(self.embeding(batch_of_letter))\n",
    "        category_plus_letter = torch.cat((batch_of_category, embeding), 1)\n",
    "\n",
    "        #sequence_length = 1\n",
    "        category_plus_letter = category_plus_letter.unsqueeze(1)\n",
    "        \n",
    "        out, (hidden, cell) = self.lstm(category_plus_letter, (hidden, cell))\n",
    "        out = self.out_fc(out)\n",
    "        out = out.squeeze(1)\n",
    "        \n",
    "        return out, (hidden, cell)\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), self.lr)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        item_dict = batch\n",
    "        loss = 0\n",
    "        batch_of_category = item_dict[\"category_tensors\"]\n",
    "\n",
    "        #to(device) needed due to some problem with PL\n",
    "        hidden = torch.zeros(self.n_layers, 1, self.hidden_size).to(self.device)\n",
    "        cell = torch.zeros(self.n_layers, 1, self.hidden_size).to(self.device)\n",
    "\n",
    "        #we loop over letters, single batch at the time \n",
    "        for t in range(item_dict[\"input_tensors\"].size(1)):\n",
    "            batch_of_letter = item_dict[\"input_tensors\"][:, t]\n",
    "            \n",
    "            output, (hidden, cell) = self(batch_of_category, batch_of_letter, hidden, cell)\n",
    "            \n",
    "            loss += self.criterion(output, item_dict[\"target_tensors\"][:, t])\n",
    "\n",
    "        loss = loss/(t+1)\n",
    "\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        cell = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a82b7e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | embeding  | Embedding        | 11 K  \n",
      "2 | lstm      | LSTM             | 940 K \n",
      "3 | out_fc    | Linear           | 18 K  \n",
      "4 | dropout   | Dropout          | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8941352aafd24e4e907428089a66d3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = NamesDatamodule(1)\n",
    "\n",
    "rnn_model = RNN(input_size=ds.n_tokens,\n",
    "            hidden_size=256,\n",
    "            embeding_size = 128, \n",
    "            n_layers=2,    \n",
    "            n_categories=ds.n_categories,\n",
    "            output_size=ds.n_tokens,\n",
    "            p=0.3)\n",
    "\n",
    "\n",
    "trainer = Trainer(max_epochs=3, \n",
    "                  logger=None,\n",
    "                  gpus=1,\n",
    "                  checkpoint_callback=False,\n",
    "                  )\n",
    "\n",
    "trainer.fit(rnn_model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc763724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de7ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135aac8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad00a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
